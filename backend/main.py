#!/usr/bin/env python3
"""
Wildfire Detection and Analysis API
Uses NASA FIRMS API for fire detection and Google's Gemma 3n for analysis
"""

import os
import json
import requests
from datetime import datetime, timedelta, UTC
from typing import List, Dict, Optional, Tuple, AsyncGenerator
from contextlib import asynccontextmanager
from fastapi import FastAPI, HTTPException, Query, UploadFile, File, Form, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse, JSONResponse
from pydantic import BaseModel, Field
from dotenv import load_dotenv
import google.generativeai as genai
from PIL import Image
import io
import base64
import uuid
from pathlib import Path

# Load environment variables
load_dotenv()

# Configuration
UPLOAD_FOLDER = Path("generated_images")
UPLOAD_FOLDER.mkdir(exist_ok=True)

class Config:
    NASA_FIRMS_API_KEY = os.getenv('NASA_FIRMS_API_KEY')
    GOOGLE_AI_STUDIO_API_KEY = os.getenv('GOOGLE_AI_STUDIO_API_KEY')
    FIRMS_BASE_URL = "https://firms.modaps.eosdis.nasa.gov/api/area/csv"
    FIRMS_SOURCE = "MODIS_NRT"  # Near Real-Time data
    FIRMS_COVERAGE = "world"    # Can be 'world' or 'us'
    FIRMS_DETECTION_TYPE = 1    # 1 = fire detection

# System prompt for wildfire analysis
WILDFIRE_SYSTEM_PROMPT = """
You are an advanced AI wildfire analysis system. Your task is to analyze satellite and sensor data to provide comprehensive wildfire intelligence. Focus on accuracy, clarity, and actionable insights.

## Response Guidelines
1. Be precise with measurements and confidence levels
2. Use clear, non-technical language for all audiences
3. Prioritize human safety and environmental protection
4. Include specific, actionable recommendations
5. Consider both immediate and long-term impacts

## Required Analysis Components
- Fire detection confidence (0-100%)
- Fire perimeter and growth patterns
- Fuel types and conditions
- Weather impact analysis
- Terrain and accessibility factors
- Potential impact on communities and infrastructure
- Wildlife and ecological considerations

## Response Format

# 🌲 WILDFIRE SITUATION REPORT

## 🔍 EXECUTIVE SUMMARY
[Concise 3-4 sentence overview of the current situation]

## 📊 DETECTION & ANALYSIS
- **Detection Confidence**: [X]% (Very High/High/Moderate/Low)
- **Fire Characteristics**:
  - Size: [acres/hectares]
  - Intensity: [Low/Moderate/High/Extreme]
  - Behavior: [Surface fire/Crown fire/Ground fire]
  - Rate of Spread: [speed/direction]

## ⚠️ RISK ASSESSMENT
- **Immediate Risk**: [Low/Moderate/High/Extreme]
- **Affected Areas**: [List key areas]
- **Critical Infrastructure at Risk**: [Highways/Power lines/Communities]
- **Evacuation Status**: [Not needed/Recommended/Mandatory in areas]

## 🚨 RECOMMENDED ACTIONS
### For Emergency Services:
1. [Specific action 1]
2. [Specific action 2]
3. [Specific action 3]

### For Residents:
1. [Specific action 1]
2. [Specific action 2]
3. [Specific action 3]

## 🌡️ ENVIRONMENTAL CONDITIONS
- **Current Weather**: [Temperature, humidity, wind speed/direction]
- **Forecast**: [Next 24-48 hours outlook]
- **Air Quality**: [Current AQI and health implications]

## 🗺️ RESOURCES DEPLOYED
- Firefighting crews: [Number/Type]
- Aircraft: [Type/Number]
- Equipment: [Type/Status]

## ℹ️ ADDITIONAL INFORMATION
- Latest update time: [Time/Date]
- Next scheduled update: [Time/Date]
- Information sources: [NASA FIRMS, Local Authorities, etc.]

---
*This report was automatically generated by the Wildfire Detection AI System on {current_date} at {current_time} UTC. For emergencies, please contact local authorities.*

*Disclaimer: This is an AI-generated analysis and should be used in conjunction with official sources and expert judgment.*
"""

# Lifespan event handler
@asynccontextmanager
async def lifespan(app: FastAPI) -> AsyncGenerator[None, None]:
    # Startup
    try:
        init_genai()
        print("Google Generative AI initialized successfully")
    except Exception as e:
        print(f"Failed to initialize Google Generative AI: {e}")
        raise
    
    yield  # App is running
    
    # Shutdown
    print("Shutting down application...")

# Initialize FastAPI app with lifespan
app = FastAPI(
    title="Wildfire Detection API",
    description="API for real-time wildfire detection and analysis using NASA FIRMS and Gemma 3n",
    version="1.0.0",
    lifespan=lifespan
)

# Configure CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Model configurations
TEXT_GEN_MODEL = 'gemma-3n-e2b-it'  # Using Gemma for text generation
IMAGE_GEN_MODEL = 'gemma-3n-e2b-it'  # Using Gemma for image generation prompts

# Initialize Google Generative AI
def init_genai():
    """Initialize the Google Generative AI client."""
    try:
        genai.configure(api_key=Config.GOOGLE_AI_STUDIO_API_KEY)
        print("Google Generative AI configured successfully with Gemma model")
    except Exception as e:
        print(f"Error initializing Google Generative AI: {e}")
        raise



# Pydantic Models
class Coordinates(BaseModel):
    lat: float = Field(..., ge=-90, le=90, description="Latitude (-90 to 90)")
    lon: float = Field(..., ge=-180, le=180, description="Longitude (-180 to 180)")

class BoundingBox(BaseModel):
    north: float = Field(..., ge=-90, le=90)
    south: float = Field(..., ge=-90, le=90)
    east: float = Field(..., ge=-180, le=180)
    west: float = Field(..., ge=-180, le=180)

class WildfireRequest(BaseModel):
    coordinates: Coordinates
    date_range: str = Field("7d", description="Time range to analyze (e.g., 7d, 30d)")
    radius_km: float = Field(50.0, description="Search radius in kilometers")
    generate_image: bool = Field(True, description="Whether to generate a visualization image")

# Helper Functions
def get_date_range(days: int) -> str:
    """Generate date range string for FIRMS API."""
    end_date = datetime.now(UTC)
    start_date = end_date - timedelta(days=days)
    return f"{start_date.strftime('%Y-%m-%d')},{end_date.strftime('%Y-%m-%d')}"

def calculate_bounding_box(lat: float, lon: float, radius_km: float) -> BoundingBox:
    """Calculate bounding box from center point and radius."""
    # Approximate conversion: 1 degree ≈ 111 km
    delta = radius_km / 111.0
    return BoundingBox(
        north=min(90, lat + delta),
        south=max(-90, lat - delta),
        east=min(180, lon + delta),
        west=max(-180, lon - delta)
    )

async def fetch_fire_data(bbox: BoundingBox, date_range: str) -> Dict:
    """Fetch fire data from NASA FIRMS API."""
    try:
        print(f"Fetching fire data for bbox: {bbox}, date_range: {date_range}")
        
        # Convert date range
        try:
            days = int(date_range.rstrip('d'))
            date_range_str = get_date_range(days)
            print(f"Converted date range: {date_range} -> {date_range_str}")
        except ValueError as ve:
            error_msg = f"Invalid date range format: {date_range}"
            print(error_msg)
            return {"status": "error", "message": error_msg}
        
        # Prepare bounding box string
        bbox_str = f"{bbox.south},{bbox.west},{bbox.north},{bbox.east}"
        print(f"Using bounding box: {bbox_str}")
        
        # Build URL and parameters
        url = f"{Config.FIRMS_BASE_URL}/{Config.NASA_FIRMS_API_KEY}/{Config.FIRMS_SOURCE}/{Config.FIRMS_COVERAGE}/{Config.FIRMS_DETECTION_TYPE}/{date_range_str}"
        params = {'bbox': bbox_str}
        
        print(f"Making request to FIRMS API: {url}")
        print(f"Query parameters: {params}")
        
        # Make the request
        try:
            response = requests.get(url, params=params, timeout=30)
            response.raise_for_status()
            print(f"Received response with status code: {response.status_code}")
        except requests.exceptions.RequestException as re:
            error_msg = f"Error making request to FIRMS API: {str(re)}"
            print(error_msg)
            if hasattr(re, 'response') and re.response is not None:
                print(f"Response content: {re.response.text}")
            return {"status": "error", "message": error_msg}
        
        # Parse CSV response
        try:
            content = response.text.strip()
            if not content:
                return {
                    "status": "success",
                    "count": 0,
                    "fires": [],
                    "bbox": bbox.model_dump(),
                    "date_range": date_range
                }
                
            lines = content.split('\n')
            if not lines:
                raise ValueError("Empty response from FIRMS API")
                
            headers = [h.strip('"') for h in lines[0].split(',')]
            fires = []
            
            for line in lines[1:]:
                if not line.strip():
                    continue
                values = [v.strip('"') for v in line.split(',')]
                if len(values) == len(headers):
                    fires.append(dict(zip(headers, values)))
            
            print(f"Successfully parsed {len(fires)} fire events")
            
            return {
                "status": "success",
                "count": len(fires),
                "fires": fires,
                "bbox": bbox.model_dump(),
                "date_range": date_range
            }
            
        except Exception as e:
            error_msg = f"Error parsing FIRMS API response: {str(e)}"
            print(error_msg)
            print(f"Response content: {response.text[:500]}...")
            return {"status": "error", "message": error_msg}
            
    except Exception as e:
        error_msg = f"Unexpected error in fetch_fire_data: {str(e)}"
        print(error_msg)
        import traceback
        traceback.print_exc()
        return {"status": "error", "message": error_msg}

@app.get("/api/image/{image_id}")
async def get_generated_image(image_id: str):
    """Retrieve a generated image by its ID."""
    image_path = UPLOAD_FOLDER / f"{image_id}.png"
    if not image_path.exists():
        raise HTTPException(status_code=404, detail="Image not found")
    return FileResponse(image_path, media_type="image/png")

async def generate_wildfire_image(analysis: str, coordinates: Coordinates, image_path: Path):
    """Generate an image based on the wildfire analysis."""
    try:
        model = genai.GenerativeModel(IMAGE_GEN_MODEL)
        
        # Create a prompt for image generation
        prompt = f"""
        Create a realistic visualization of a wildfire risk assessment for a location at 
        latitude {coordinates.lat}, longitude {coordinates.lon}.
        
        Analysis Summary:
        {analysis[:1000]}...
        
        The image should show:
        - A map-like visualization of the area
        - Fire risk level indicators
        - Key risk factors
        - A professional, clean design suitable for a wildfire monitoring dashboard
        """
        
        # Generate the image
        response = await model.generate_content_async(
            prompt,
            generation_config={
                "temperature": 0.7,
                "top_p": 0.8,
                "top_k": 40,
                "max_output_tokens": 2048,
            },
        )
        
        # Save the image
        if hasattr(response, 'images') and response.images:
            image_data = response.images[0]
            with open(image_path, 'wb') as f:
                f.write(image_data)
            return str(image_path)
        return None
        
    except Exception as e:
        print(f"Error generating wildfire image: {e}")
        return None

@app.post("/api/analyze")
async def analyze_wildfire(request: WildfireRequest, background_tasks: BackgroundTasks):
    """Analyze wildfire data for a specific location."""
    try:
        # Check required configurations
        if not Config.NASA_FIRMS_API_KEY:
            raise ValueError("NASA FIRMS API key not configured")
        if not Config.GOOGLE_AI_STUDIO_API_KEY:
            raise ValueError("Google AI Studio API key not configured")
        
        print(f"Starting analysis for coordinates: {request.coordinates}")
        
        # Get bounding box
        try:
            bbox = calculate_bounding_box(
                request.coordinates.lat,
                request.coordinates.lon,
                request.radius_km
            )
            print(f"Calculated bounding box: {bbox}")
        except Exception as e:
            raise ValueError(f"Error calculating bounding box: {str(e)}")
        
        # Fetch fire data
        try:
            print("Fetching fire data...")
            fire_data = await fetch_fire_data(bbox, request.date_range)
            if fire_data["status"] != "success":
                error_msg = fire_data.get("message", "Unknown error fetching fire data")
                print(f"Error in fetch_fire_data: {error_msg}")
                raise ValueError(f"Failed to fetch fire data: {error_msg}")
            print(f"Fetched {fire_data.get('count', 0)} fire events")
        except Exception as e:
            raise ValueError(f"Error in fetch_fire_data: {str(e)}")
        
        # Prepare analysis prompt with system instructions
        try:
            prompt = f"""
            {WILDFIRE_SYSTEM_PROMPT}
            
            Location: Latitude {request.coordinates.lat}, Longitude {request.coordinates.lon}
            Date Range: {request.date_range}
            Radius: {request.radius_km} km
            
            Fire Data:
            {json.dumps(fire_data.get('fires', []), indent=2)}
            
            Please analyze this data and provide a detailed report.
            """
            print("Prepared analysis prompt")
        except Exception as e:
            raise ValueError(f"Error preparing analysis prompt: {str(e)}")
        
        # Generate analysis using Gemma
        try:
            print("Generating analysis with Gemma...")
            model = genai.GenerativeModel(TEXT_GEN_MODEL)
            response = await model.generate_content_async(
                prompt,
                generation_config={
                    "temperature": 0.7,
                    "top_p": 0.8,
                    "top_k": 40,
                    "max_output_tokens": 2048,
                },
            )
            analysis = response.text
            print("Successfully generated analysis")
        except Exception as e:
            raise ValueError(f"Error generating analysis with Gemma: {str(e)}")
        
        # Prepare response
        response_data = {
            "status": "success",
            "analysis": analysis,
            "fire_data": fire_data
        }
        
        # Generate image in background if requested
        if request.generate_image:
            try:
                image_id = str(uuid.uuid4())
                image_path = UPLOAD_FOLDER / f"{image_id}.png"
                response_data["image_id"] = image_id
                
                print(f"Queueing background image generation with ID: {image_id}")
                
                # Run image generation in background
                background_tasks.add_task(
                    generate_wildfire_image,
                    analysis=analysis,
                    coordinates=request.coordinates,
                    image_path=image_path
                )
            except Exception as e:
                print(f"Warning: Failed to queue image generation: {str(e)}")
                # Don't fail the whole request if image generation fails
        
        print("Analysis completed successfully")
        return response_data
    
    except ValueError as ve:
        error_msg = f"Validation error: {str(ve)}"
        print(error_msg)
        raise HTTPException(status_code=400, detail=error_msg)
    except Exception as e:
        error_msg = f"Unexpected error: {str(e)}"
        print(error_msg)
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=error_msg)

@app.post("/api/tts")
async def text_to_speech(request: dict):
    """Convert text to speech using Gemma."""
    try:
        text = request.get("text", "")
        if not text:
            raise HTTPException(status_code=400, detail="No text provided")
            
        # For now, we'll return the text as is since we can't directly generate speech with Gemma
        # In a production environment, you would integrate with a TTS service
        return {
            "status": "success",
            "text": text,
            "message": "Text received for TTS processing"
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error processing TTS request: {str(e)}")

@app.get("/api/health")
async def health_check():
    """Health check endpoint."""
    return {
        "status": "ok",
        "version": "1.0.0",
        "models": {
            "text_generation": TEXT_GEN_MODEL,
            "image_generation": IMAGE_GEN_MODEL,
            "tts": "gemma-3n-e2b-it"
        }
    }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)